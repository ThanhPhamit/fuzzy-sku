"""
OpenSearch Indexer for Japanese SKU Master Data
Optimized for fuzzy matching with Japanese text variations
"""

from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import boto3
import csv
import os
from datetime import datetime


class JapaneseSKUIndexer:
    def __init__(self):
        self.aws_profile = "welfan-lg-mfa"
        self.aws_region = "ap-northeast-3"
        self.endpoint = (
            "search-fuzzy-sku-ppba34qtds6ocweyl62wmgv5we.aos.ap-northeast-3.on.aws"
        )
        self.index_name = "sku-master"
        self.client = None

    def connect(self):
        """Connect to OpenSearch with AWS authentication"""
        try:
            print(f"ğŸ”§ Connecting with profile: {self.aws_profile}")

            session = boto3.Session(profile_name=self.aws_profile)
            credentials = session.get_credentials()

            if not credentials:
                raise Exception(
                    f"AWS credentials not found for profile: {self.aws_profile}"
                )

            awsauth = AWS4Auth(
                credentials.access_key,
                credentials.secret_key,
                self.aws_region,
                "es",
                session_token=credentials.token,
            )

            self.client = OpenSearch(
                hosts=[{"host": self.endpoint, "port": 443}],
                http_auth=awsauth,
                use_ssl=True,
                verify_certs=True,
                connection_class=RequestsHttpConnection,
                timeout=30,
            )

            # Test connection
            health = self.client.cluster.health()
            print(f"âœ… Connected! Cluster: {health['status']}")
            return True

        except Exception as e:
            print(f"âŒ Connection failed: {e}")
            return False

    def create_optimized_index(self):
        """Create index optimized for Japanese SKU fuzzy matching"""

        # Advanced mapping for Japanese text with multiple analyzers
        mapping = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 1,
                "index.max_ngram_diff": 7,
                "analysis": {
                    "char_filter": {
                        "normalize_chars": {
                            "type": "mapping",
                            "mappings": [
                                # Zenkaku to Hankaku numbers
                                "ï¼ => 0",
                                "ï¼‘ => 1",
                                "ï¼’ => 2",
                                "ï¼“ => 3",
                                "ï¼” => 4",
                                "ï¼• => 5",
                                "ï¼– => 6",
                                "ï¼— => 7",
                                "ï¼˜ => 8",
                                "ï¼™ => 9",
                                # Zenkaku to Hankaku alphabets
                                "ï¼¡ => A",
                                "ï¼¢ => B",
                                "ï¼£ => C",
                                "ï¼¤ => D",
                                "ï¼¥ => E",
                                "ï¼¦ => F",
                                "ï¼§ => G",
                                "ï¼¨ => H",
                                "ï¼© => I",
                                "ï¼ª => J",
                                "ï¼« => K",
                                "ï¼¬ => L",
                                "ï¼­ => M",
                                "ï¼® => N",
                                "ï¼¯ => O",
                                "ï¼° => P",
                                "ï¼± => Q",
                                "ï¼² => R",
                                "ï¼³ => S",
                                "ï¼´ => T",
                                "ï¼µ => U",
                                "ï¼¶ => V",
                                "ï¼· => W",
                                "ï¼¸ => X",
                                "ï¼¹ => Y",
                                "ï¼º => Z",
                                # Lowercase versions
                                "ï½ => a",
                                "ï½‚ => b",
                                "ï½ƒ => c",
                                "ï½„ => d",
                                "ï½… => e",
                                "ï½† => f",
                                "ï½‡ => g",
                                "ï½ˆ => h",
                                "ï½‰ => i",
                                "ï½Š => j",
                                "ï½‹ => k",
                                "ï½Œ => l",
                                "ï½ => m",
                                "ï½ => n",
                                "ï½ => o",
                                "ï½ => p",
                                "ï½‘ => q",
                                "ï½’ => r",
                                "ï½“ => s",
                                "ï½” => t",
                                "ï½• => u",
                                "ï½– => v",
                                "ï½— => w",
                                "ï½˜ => x",
                                "ï½™ => y",
                                "ï½š => z",
                                # Special characters
                                "ï¼ˆ => (",
                                "ï¼‰ => )",
                                "ï¼ => -",
                                "ã€€ => ",
                                "ï½ => ~",
                                "ãƒ» => ãƒ»",
                                "ï¼ => /",
                                "ï¼‹ => +",
                                "ï¼ => =",
                            ],
                        },
                        "katakana_hiragana": {
                            "type": "mapping",
                            "mappings": [
                                # Basic katakana to hiragana (46 characters)
                                "ã‚¢ => ã‚",
                                "ã‚¤ => ã„",
                                "ã‚¦ => ã†",
                                "ã‚¨ => ãˆ",
                                "ã‚ª => ãŠ",
                                "ã‚« => ã‹",
                                "ã‚­ => ã",
                                "ã‚¯ => ã",
                                "ã‚± => ã‘",
                                "ã‚³ => ã“",
                                "ã‚µ => ã•",
                                "ã‚· => ã—",
                                "ã‚¹ => ã™",
                                "ã‚» => ã›",
                                "ã‚½ => ã",
                                "ã‚¿ => ãŸ",
                                "ãƒ => ã¡",
                                "ãƒ„ => ã¤",
                                "ãƒ† => ã¦",
                                "ãƒˆ => ã¨",
                                "ãƒŠ => ãª",
                                "ãƒ‹ => ã«",
                                "ãƒŒ => ã¬",
                                "ãƒ => ã­",
                                "ãƒ => ã®",
                                "ãƒ => ã¯",
                                "ãƒ’ => ã²",
                                "ãƒ• => ãµ",
                                "ãƒ˜ => ã¸",
                                "ãƒ› => ã»",
                                "ãƒ => ã¾",
                                "ãƒŸ => ã¿",
                                "ãƒ  => ã‚€",
                                "ãƒ¡ => ã‚",
                                "ãƒ¢ => ã‚‚",
                                "ãƒ¤ => ã‚„",
                                "ãƒ¦ => ã‚†",
                                "ãƒ¨ => ã‚ˆ",
                                "ãƒ© => ã‚‰",
                                "ãƒª => ã‚Š",
                                "ãƒ« => ã‚‹",
                                "ãƒ¬ => ã‚Œ",
                                "ãƒ­ => ã‚",
                                "ãƒ¯ => ã‚",
                                "ãƒ² => ã‚’",
                                "ãƒ³ => ã‚“",
                                # Dakuten (voiced) variants
                                "ã‚¬ => ãŒ",
                                "ã‚® => ã",
                                "ã‚° => ã",
                                "ã‚² => ã’",
                                "ã‚´ => ã”",
                                "ã‚¶ => ã–",
                                "ã‚¸ => ã˜",
                                "ã‚º => ãš",
                                "ã‚¼ => ãœ",
                                "ã‚¾ => ã",
                                "ãƒ€ => ã ",
                                "ãƒ‚ => ã¢",
                                "ãƒ… => ã¥",
                                "ãƒ‡ => ã§",
                                "ãƒ‰ => ã©",
                                "ãƒ => ã°",
                                "ãƒ“ => ã³",
                                "ãƒ– => ã¶",
                                "ãƒ™ => ã¹",
                                "ãƒœ => ã¼",
                                # Handakuten (semi-voiced) variants
                                "ãƒ‘ => ã±",
                                "ãƒ” => ã´",
                                "ãƒ— => ã·",
                                "ãƒš => ãº",
                                "ãƒ => ã½",
                                # Small characters
                                "ã‚¡ => ã",
                                "ã‚£ => ãƒ",
                                "ã‚¥ => ã…",
                                "ã‚§ => ã‡",
                                "ã‚© => ã‰",
                                "ãƒƒ => ã£",
                                "ãƒ£ => ã‚ƒ",
                                "ãƒ¥ => ã‚…",
                                "ãƒ§ => ã‚‡",
                                "ãƒ® => ã‚",
                                # Special katakana
                                "ãƒ´ => ã‚”",
                                # ADD missing characters:
                                # Extended katakana (for foreign words)
                                "ãƒ· => ã‚ã‚™",  # VA (rare)
                                "ãƒ¸ => ã‚ã‚™",  # VI (rare)
                                "ãƒ¹ => ã‚‘ã‚™",  # VE (rare)
                                "ãƒº => ã‚’ã‚™",  # VO (rare)
                                # Long vowel mark (keep as-is)
                                "ãƒ¼ => ãƒ¼",  # ChÅonpu - important for SKUs!
                                # Iteration marks
                                "ãƒ½ => ã‚",  # Katakana iteration mark
                                "ãƒ¾ => ã‚",  # Katakana voiced iteration mark
                                # Middle dot (keep as-is for product names)
                                "ãƒ» => ãƒ»",  # Nakaguro - used in product names
                                # Small TSU variants (for foreign sounds)
                                "ãƒ¶ => ãŒ",  # Small KE (used in counters)
                                "ãƒµ => ã‹",  # Small KA
                                # Additional small vowels (modern usage)
                                "ã‡° => ã",  # Small KU
                                "ã‡± => ã—",  # Small SHI
                                "ã‡² => ã™",  # Small SU
                                "ã‡³ => ã¨",  # Small TO
                            ],
                        },
                    },
                    "tokenizer": {
                        "japanese_char_ngram": {
                            "type": "ngram",
                            "min_gram": 2,
                            "max_gram": 4,
                            "token_chars": ["letter", "digit"],
                        }
                    },
                    "analyzer": {
                        "japanese_standard": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "kuromoji_part_of_speech",
                                "cjk_width",
                                "lowercase",
                            ],
                        },
                        "japanese_ngram": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "cjk_width",
                                "lowercase",
                                "edge_ngram_filter",
                            ],
                        },
                        "japanese_fuzzy": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "japanese_char_ngram",
                            "filter": [
                                "cjk_width",
                                "lowercase",
                            ],
                        },
                        "japanese_partial": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "cjk_width",
                                "lowercase",
                                "char_ngram_filter",
                            ],
                        },
                        "exact_match": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "keyword",
                            "filter": ["cjk_width", "lowercase"],
                        },
                        "reading_analyzer": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "cjk_width",
                                "lowercase",
                            ],
                        },
                        "synonym_analyzer": {
                            "type": "custom",
                            "char_filter": ["normalize_chars", "katakana_hiragana"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "cjk_width",
                                "lowercase",
                                "product_synonyms",
                            ],
                        },
                        "romaji_analyzer": {
                            "type": "custom",
                            "char_filter": ["normalize_chars"],
                            "tokenizer": "kuromoji_tokenizer",
                            "filter": [
                                "kuromoji_baseform",
                                "cjk_width",
                                "lowercase",
                                "asciifolding",
                            ],
                        },
                    },
                    "filter": {
                        "edge_ngram_filter": {
                            "type": "edge_ngram",
                            "min_gram": 2,
                            "max_gram": 8,
                        },
                        "char_ngram_filter": {
                            "type": "ngram",
                            "min_gram": 2,
                            "max_gram": 4,
                        },
                        "asciifolding": {
                            "type": "asciifolding",
                            "preserve_original": True,
                        },
                        "product_synonyms": {
                            "type": "synonym",
                            "synonyms": [
                                "ä»‹è­·ç”¨ãŠã‚€ã¤,å¤§äººç”¨ãŠã‚€ã¤,å¤±ç¦ç”¨ãŠã‚€ã¤,ã‚¢ãƒ€ãƒ«ãƒˆãƒ€ã‚¤ãƒ‘ãƒ¼,ç´™ãŠã‚€ã¤",
                                "å°¿å–ã‚Šãƒ‘ãƒƒãƒ‰,å°¿ã¨ã‚Šãƒ‘ãƒƒãƒ‰,å¤±ç¦ãƒ‘ãƒƒãƒ‰,ä»‹è­·ãƒ‘ãƒƒãƒ‰",
                                "ãƒãƒ¼ã‚¿ãƒ–ãƒ«ãƒˆã‚¤ãƒ¬,ç°¡æ˜“ãƒˆã‚¤ãƒ¬,ä»‹è­·ãƒˆã‚¤ãƒ¬,ç§»å‹•å¼ãƒˆã‚¤ãƒ¬",
                                "æ¸©æ°´æ´—æµ„ä¾¿åº§,ã‚¦ã‚©ã‚·ãƒ¥ãƒ¬ãƒƒãƒˆ,ã‚·ãƒ£ãƒ¯ãƒ¼ãƒˆã‚¤ãƒ¬",
                                "ä¾¿å™¨,ä¾¿åº§,ä¾¿åº§å®¹å™¨,ãƒ™ãƒƒãƒ‰ãƒ‘ãƒ³",
                                "è»Šã„ã™,è»Šæ¤…å­,è»Šã‚¤ã‚¹,ã‚¦ã‚£ãƒ¼ãƒ«ãƒã‚§ã‚¢",
                                "æ­©è¡Œå™¨,ã‚·ãƒ«ãƒãƒ¼ã‚«ãƒ¼,ãƒ­ãƒ¬ãƒ¼ã‚¿,ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚¿,ãƒ­ãƒ¼ãƒ©ãƒˆãƒ¼ãƒ«",
                                "æ–,ã¤ãˆ,ã‚¹ãƒ†ãƒƒã‚­,æ­©è¡Œæ–",
                                "ç§»ä¹—ç”¨ãƒªãƒ•ãƒˆ,ä»‹è­·ãƒªãƒ•ãƒˆ,ãƒªãƒ•ã‚¿ãƒ¼,ã¤ã‚Šä¸Šã’ãƒªãƒ•ãƒˆ",
                                "ã‚·ãƒ‹ã‚¢ã‚«ãƒ¼,é›»å‹•ã‚·ãƒ‹ã‚¢ã‚«ãƒ¼,é›»å‹•ã‚«ãƒ¼ãƒˆ,ãƒ¢ãƒ“ãƒªãƒ†ã‚£ã‚¹ã‚¯ãƒ¼ã‚¿ãƒ¼",
                                "ä»‹è­·ãƒ™ãƒƒãƒ‰,ä»‹è­·ç”¨ãƒ™ãƒƒãƒ‰,é›»å‹•ãƒ™ãƒƒãƒ‰,ãƒªã‚¯ãƒ©ã‚¤ãƒ‹ãƒ³ã‚°ãƒ™ãƒƒãƒ‰",
                                "ä½“åœ§åˆ†æ•£ãƒãƒƒãƒˆãƒ¬ã‚¹,ã‚¨ã‚¢ãƒãƒƒãƒˆãƒ¬ã‚¹,è¤¥ç˜¡äºˆé˜²ãƒãƒƒãƒˆãƒ¬ã‚¹,è¤¥ç˜¡ãƒãƒƒãƒˆ",
                                "é›¢åºŠã‚»ãƒ³ã‚µãƒ¼,è¦‹å®ˆã‚Šã‚»ãƒ³ã‚µãƒ¼,å¾˜å¾Šã‚»ãƒ³ã‚µãƒ¼,èµ·ãä¸ŠãŒã‚Šã‚»ãƒ³ã‚µãƒ¼",
                                "ã‚·ãƒ£ãƒ¯ãƒ¼ãƒã‚§ã‚¢,å…¥æµ´ç”¨ã„ã™,å…¥æµ´æ¤…å­,é¢¨å‘‚ã„ã™",
                                "å£è…”ã‚±ã‚¢,å£è…”æ¸…æ‹­,å£è…”ç”¨ã‚¹ãƒãƒ³ã‚¸,ã‚ªãƒ¼ãƒ©ãƒ«ã‚±ã‚¢",
                                "ä½¿ã„æ¨ã¦æ‰‹è¢‹,ä½¿ã„åˆ‡ã‚Šæ‰‹è¢‹,ãƒ‹ãƒˆãƒªãƒ«æ‰‹è¢‹,ãƒ©ãƒ†ãƒƒã‚¯ã‚¹æ‰‹è¢‹,ãƒ“ãƒ‹ãƒ¼ãƒ«æ‰‹è¢‹",
                                "ãƒã‚¹ã‚¯,ã‚µãƒ¼ã‚¸ã‚«ãƒ«ãƒã‚¹ã‚¯,ä»‹è­·ç”¨ãƒã‚¹ã‚¯,ä¸ç¹”å¸ƒãƒã‚¹ã‚¯",
                                "æ¶ˆæ¯’æ¶²,ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«æ¶ˆæ¯’,é™¤èŒæ¶²,ã‚¨ã‚¿ãƒãƒ¼ãƒ«æ¶ˆæ¯’",
                                "ä½“æ¸©è¨ˆ,ãƒ‡ã‚¸ã‚¿ãƒ«ä½“æ¸©è¨ˆ,éæ¥è§¦ä½“æ¸©è¨ˆ,ã§ã“æ¸©åº¦è¨ˆ",
                                "è¡€åœ§è¨ˆ,ä¸Šè…•å¼è¡€åœ§è¨ˆ,æ‰‹é¦–å¼è¡€åœ§è¨ˆ",
                                "ãƒ‘ãƒ«ã‚¹ã‚ªã‚­ã‚·ãƒ¡ãƒ¼ã‚¿ãƒ¼,ãƒ‘ãƒ«ã‚¹ã‚ªã‚­ã‚·ãƒ¡ãƒ¼ã‚¿,è¡€ä¸­é…¸ç´ æ¿ƒåº¦è¨ˆ,SpO2è¨ˆ",
                                "ã¨ã‚ã¿å‰¤,å¢—ç²˜å‰¤,ãƒˆãƒ­ãƒŸå‰¤",
                                "æ „é¤Šè£œåŠ©é£Ÿå“,ä»‹è­·é£Ÿ,ã‚½ãƒ•ãƒˆé£Ÿ,ãƒŸã‚­ã‚µãƒ¼é£Ÿ",
                                "è‡ªå‹•,ã‚ªãƒ¼ãƒˆ,ã‚¸ãƒ‰ã‚¦,ã‚ªãƒ¼ãƒˆãƒãƒãƒƒã‚¯",
                                "ã‚»ãƒ³ã‚µãƒ¼,æ„ŸçŸ¥å™¨,ã‚»ãƒ³ã‚µ,èµ¤å¤–ç·šã‚»ãƒ³ã‚µãƒ¼",
                                "ãƒãƒ¼ã‚¿ãƒ–ãƒ«,æŒã¡é‹ã³,ç§»å‹•å¼,æºå¸¯",
                                "åºŠãšã‚Œé˜²æ­¢,è¤¥ç˜¡äºˆé˜²,ã˜ã‚‡ããã†äºˆé˜²",
                            ],
                        },
                    },
                },
            },
            "mappings": {
                "properties": {
                    "id": {"type": "integer"},
                    "sku_name": {
                        "type": "text",
                        "analyzer": "japanese_standard",
                        "search_analyzer": "japanese_partial",
                        "fields": {
                            "exact": {"type": "text", "analyzer": "exact_match"},
                            "ngram": {"type": "text", "analyzer": "japanese_ngram"},
                            "fuzzy": {"type": "text", "analyzer": "japanese_fuzzy"},
                            "partial": {"type": "text", "analyzer": "japanese_partial"},
                            "synonym": {"type": "text", "analyzer": "synonym_analyzer"},
                            "romaji": {"type": "text", "analyzer": "romaji_analyzer"},
                            "keyword": {"type": "keyword", "ignore_above": 256},
                        },
                    },
                    "original_text": {
                        "type": "text",
                        "analyzer": "japanese_standard",
                        "fields": {"keyword": {"type": "keyword", "ignore_above": 256}},
                    },
                    "reading": {
                        "type": "text",
                        "analyzer": "reading_analyzer",
                        "search_analyzer": "japanese_fuzzy",
                        "fields": {
                            "keyword": {"type": "keyword", "ignore_above": 256},
                            "romaji": {"type": "text", "analyzer": "romaji_analyzer"},
                        },
                    },
                    "category": {"type": "keyword"},
                    "created_at": {"type": "date"},
                    "updated_at": {"type": "date"},
                }
            },
        }

        try:
            if self.client.indices.exists(index=self.index_name):
                print(f"âš ï¸  Index '{self.index_name}' exists")
                choice = input("Delete and recreate? (y/N): ").lower()
                if choice in ["y", "yes"]:
                    self.client.indices.delete(index=self.index_name)
                    print(f"ğŸ—‘ï¸  Deleted: {self.index_name}")
                else:
                    return True

            self.client.indices.create(index=self.index_name, body=mapping)
            print(f"âœ… Created optimized index: {self.index_name}")
            return True

        except Exception as e:
            print(f"âŒ Index creation failed: {e}")
            return False

    def index_sku_data(self, csv_file="TM_SYOHIN_202509291906.csv"):
        """Index SKU master data from CSV with batch processing"""

        if not os.path.exists(csv_file):
            print(f"âŒ File not found: {csv_file}")
            return False

        try:
            print(f"ğŸ“„ Reading: {csv_file}")
            products = []

            with open(csv_file, "r", encoding="utf-8") as file:
                reader = csv.reader(file)
                header = next(reader, None)
                print(f"Header: {header}")

                for row_id, row in enumerate(reader, start=1):
                    if row and row[0].strip():
                        sku_name = row[0].strip()

                        # Extract product info for better categorization
                        category = "unknown"
                        if any(x in sku_name for x in ["ä¾¿åº§", "ãƒˆã‚¤ãƒ¬", "KX", "FX"]):
                            category = "toilet_products"
                        elif any(x in sku_name for x in ["æš–æˆ¿", "æ¸©æ°´"]):
                            category = "heating_products"
                        elif any(x in sku_name for x in ["ãƒãƒ¼ã‚¿ãƒ–ãƒ«", "ãƒ•ãƒ¬ãƒ¼ãƒ "]):
                            category = "portable_products"

                        product = {
                            "id": row_id,
                            "sku_name": sku_name,
                            "original_text": sku_name,
                            "category": category,
                            "created_at": datetime.now().isoformat(),
                            "updated_at": datetime.now().isoformat(),
                        }
                        products.append(product)

            print(f"ğŸ“Š Loaded {len(products)} SKU records")

            # Bulk index with progress tracking
            batch_size = 100
            total_indexed = 0

            for i in range(0, len(products), batch_size):
                batch = products[i : i + batch_size]
                bulk_body = []

                for product in batch:
                    bulk_body.extend(
                        [
                            {
                                "index": {
                                    "_index": self.index_name,
                                    "_id": product["id"],
                                }
                            },
                            product,
                        ]
                    )

                response = self.client.bulk(body=bulk_body)

                # Check for errors
                errors = 0
                if response.get("errors"):
                    for item in response["items"]:
                        if "index" in item and "error" in item["index"]:
                            errors += 1
                            print(
                                f"   Error ID {item['index']['_id']}: {item['index']['error']['reason']}"
                            )

                total_indexed += len(batch) - errors
                batch_num = (i // batch_size) + 1
                print(
                    f"ğŸ“ Batch {batch_num}: {len(batch) - errors}/{len(batch)} indexed (Total: {total_indexed})"
                )

            # Refresh index for immediate search
            self.client.indices.refresh(index=self.index_name)
            print(f"ğŸ‰ Successfully indexed {total_indexed} SKU records")

            # Show index statistics
            stats = self.client.indices.stats(index=self.index_name)
            doc_count = stats["indices"][self.index_name]["total"]["docs"]["count"]
            size = stats["indices"][self.index_name]["total"]["store"]["size_in_bytes"]
            print(f"ğŸ“ˆ Index stats: {doc_count} docs, {size:,} bytes")

            return True

        except Exception as e:
            print(f"âŒ Indexing failed: {e}")
            return False

    def validate_index(self):
        """Validate indexed data with sample searches"""
        print("\nğŸ” Validating index with sample searches...")

        test_cases = [
            "FX-1",
            "ä¾¿åº§",
            "æš–æˆ¿",
            "KX-SDR",
            "ãƒ¡ã‚¤ã‚¸",  # This might not exist but tests fuzzy matching
            "ãƒ¡ã‚¤ã‚¸ãƒãƒ©ãƒ³ã‚¹ã‚½ãƒ•ãƒˆ",  # Test case for partial matching
        ]

        for query in test_cases:
            try:
                # Test multiple field searches for better Japanese matching
                response = self.client.search(
                    index=self.index_name,
                    body={
                        "query": {
                            "bool": {
                                "should": [
                                    {"match": {"sku_name": query}},
                                    {"match": {"sku_name.ngram": query}},
                                    {"match": {"sku_name.fuzzy": query}},
                                    {"match": {"sku_name.partial": query}},
                                ]
                            }
                        },
                        "size": 5,
                    },
                )

                hits = len(response["hits"]["hits"])
                total = response["hits"]["total"]["value"]
                print(f"   '{query}': {hits} results (total: {total})")

                # Show top result for debugging
                if hits > 0:
                    top_result = response["hits"]["hits"][0]
                    score = top_result["_score"]
                    name = top_result["_source"]["sku_name"]
                    print(f"      â†’ Top: '{name}' (score: {score:.2f})")

            except Exception as e:
                print(f"   '{query}': Error - {e}")

        print("âœ… Index validation complete")


def main():
    """Main indexing process"""
    print("ğŸš€ Japanese SKU Master Data Indexer")
    print("=" * 50)
    print("ğŸ“‹ Optimized for:")
    print("   - Japanese text variations (å…¨è§’/åŠè§’)")
    print("   - Kanji/Hiragana/Katakana fuzzy matching")
    print("   - Multi-step AI search reasoning")
    print("   - Fast candidate retrieval")
    print("")

    indexer = JapaneseSKUIndexer()

    # Step 1: Connect
    if not indexer.connect():
        print("ğŸ’¥ Connection failed. Check troubleshooter.")
        return

    # Step 2: Create optimized index
    if not indexer.create_optimized_index():
        print("ğŸ’¥ Index creation failed.")
        return

    # Step 3: Index SKU data
    if not indexer.index_sku_data():
        print("ğŸ’¥ Data indexing failed.")
        return

    # Step 4: Validate
    indexer.validate_index()

    print("\nğŸ‰ Indexing complete! Ready for fuzzy search testing.")
    print("Next step: Run 'python fuzzy_search_tester.py'")


if __name__ == "__main__":
    main()
